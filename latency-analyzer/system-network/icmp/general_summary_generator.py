#!/usr/bin/env python3
"""
é€šç”¨å»¶è¿Ÿåˆ†æSummaryç”Ÿæˆå™¨
åˆ†æé€šç”¨å»¶è¿Ÿåˆ†æå™¨ç”Ÿæˆçš„æ•°æ®ï¼Œç”Ÿæˆå»¶è¿Ÿåˆ†å¸ƒå’Œstageåˆ†å¸ƒæŠ¥å‘Š
"""

import json
import statistics
from collections import defaultdict, Counter

class GeneralSummaryGenerator:
    def __init__(self, analysis_file):
        self.analysis_file = analysis_file
        self.data = None
        
    def load_data(self):
        """åŠ è½½åˆ†ææ•°æ®"""
        with open(self.analysis_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        print(f"å·²åŠ è½½åˆ†ææ•°æ®: {self.analysis_file}")
        
    def get_latency_range_label(self, latency_us):
        """å°†å»¶è¿Ÿ(us)åˆ†ç±»åˆ°åˆé€‚çš„åŒºé—´"""
        latency_ms = latency_us / 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        if latency_ms < 10:
            return "0-10ms"
        elif latency_ms < 100:
            return "10-100ms"
        elif latency_ms < 500:
            return "100-500ms"
        elif latency_ms < 1000:
            return "500-1000ms"
        elif latency_ms < 3000:
            return "1000-3000ms"
        elif latency_ms < 60000:
            return "3000-60000ms"
        else:
            return ">60000ms"
    
    def get_range_order(self):
        """è·å–åŒºé—´çš„æ˜¾ç¤ºé¡ºåº"""
        return [
            "0-10ms",
            "10-100ms",
            "100-500ms",
            "500-1000ms", 
            "1000-3000ms",
            "3000-60000ms",
            ">60000ms"
        ]
    
    def analyze_sessions(self):
        """åˆ†ææ‰€æœ‰node pairsçš„sessionæ•°æ®"""
        analysis = self.data['analysis']
        valid_sessions = analysis.get('valid_sessions', [])
        dropped_sessions = analysis.get('dropped_sessions', [])
        node_pairs = analysis.get('node_pairs', [])
        
        # æ€»ä½“åˆ†æ
        all_max_latencies = []
        valid_stage_distribution = Counter()
        valid_range_distribution = Counter()
        valid_range_distribution_above_10ms = Counter()
        
        # æŒ‰node pairåˆ†æ
        pair_analysis = {}
        
        for session in valid_sessions:
            max_latency = session.get('max_latency', 0)
            pair_name = session.get('pair_name', 'unknown')
            
            # åˆå§‹åŒ–pairåˆ†æ
            if pair_name not in pair_analysis:
                pair_analysis[pair_name] = {
                    'latencies': [],
                    'stage_distribution': Counter(),
                    'range_distribution': Counter(),
                    'range_distribution_above_10ms': Counter()
                }
            
            if max_latency > 0:
                all_max_latencies.append(max_latency)
                pair_analysis[pair_name]['latencies'].append(max_latency)
                
                # åˆ†ç±»åˆ°å»¶è¿ŸåŒºé—´
                range_label = self.get_latency_range_label(max_latency)
                valid_range_distribution[range_label] += 1
                pair_analysis[pair_name]['range_distribution'][range_label] += 1
                
                # åªç»Ÿè®¡10msä»¥ä¸Šçš„å»¶è¿Ÿåˆ†å¸ƒå’Œstageåˆ†å¸ƒ
                latency_ms = max_latency / 1000
                if latency_ms >= 10:
                    valid_range_distribution_above_10ms[range_label] += 1
                    pair_analysis[pair_name]['range_distribution_above_10ms'][range_label] += 1
                    
                    # ç»Ÿè®¡æœ€å¤§å»¶è¿Ÿæ‰€åœ¨çš„stage (åªç»Ÿè®¡10msä»¥ä¸Š)
                    max_stage = session.get('max_stage')
                    if max_stage:
                        valid_stage_distribution[max_stage] += 1
                        pair_analysis[pair_name]['stage_distribution'][max_stage] += 1
        
        # åˆ†æä¸¢åŒ…sessions
        dropped_stage_distribution = Counter()
        drop_reason_distribution = Counter()
        
        for session in dropped_sessions:
            # ç»Ÿè®¡æœ€å¤§å»¶è¿Ÿæ‰€åœ¨çš„stage
            max_stage = session.get('max_stage')
            if max_stage:
                dropped_stage_distribution[max_stage] += 1
            
            # ç»Ÿè®¡ä¸¢åŒ…åŸå› 
            drop_details = session.get('drop_details', [])
            for reason in drop_details:
                drop_reason_distribution[reason] += 1
        
        # ç”Ÿæˆæ€»ä½“ç»Ÿè®¡ç»“æœ
        summary = {
            'node_pairs': node_pairs,
            'total_sessions': analysis.get('total_sessions', 0),
            'matched_sessions': analysis.get('matched_sessions', 0),
            'outgoing_only': analysis.get('outgoing_only', 0),
            'incoming_only': analysis.get('incoming_only', 0),
            'overall_analysis': {
                'total_valid_sessions': len(valid_sessions),
                'sessions_with_latency': len(all_max_latencies),
                'latency_distribution': dict(valid_range_distribution),
                'latency_distribution_above_10ms': dict(valid_range_distribution_above_10ms),
                'stage_distribution': dict(valid_stage_distribution)
            },
            'dropped_sessions_analysis': {
                'total_dropped_sessions': len(dropped_sessions),
                'stage_distribution': dict(dropped_stage_distribution),
                'drop_reason_distribution': dict(drop_reason_distribution)
            },
            'pair_analysis': {}
        }
        
        # æ·»åŠ æ€»ä½“å»¶è¿Ÿç»Ÿè®¡
        if all_max_latencies:
            summary['overall_analysis']['latency_statistics'] = {
                'count': len(all_max_latencies),
                'mean': statistics.mean(all_max_latencies),
                'median': statistics.median(all_max_latencies),
                'min': min(all_max_latencies),
                'max': max(all_max_latencies),
                'std': statistics.stdev(all_max_latencies) if len(all_max_latencies) > 1 else 0,
                'p95': sorted(all_max_latencies)[int(len(all_max_latencies) * 0.95)] if len(all_max_latencies) > 1 else all_max_latencies[0],
                'p99': sorted(all_max_latencies)[int(len(all_max_latencies) * 0.99)] if len(all_max_latencies) > 1 else all_max_latencies[0]
            }
        
        # ç”Ÿæˆæ¯ä¸ªpairçš„ç»Ÿè®¡
        for pair_name, pair_data in pair_analysis.items():
            latencies = pair_data['latencies']
            if latencies:
                pair_stats = {
                    'total_sessions': len(latencies),
                    'latency_distribution': dict(pair_data['range_distribution']),
                    'latency_distribution_above_10ms': dict(pair_data['range_distribution_above_10ms']),
                    'stage_distribution': dict(pair_data['stage_distribution']),
                    'latency_statistics': {
                        'count': len(latencies),
                        'mean': statistics.mean(latencies),
                        'median': statistics.median(latencies),
                        'min': min(latencies),
                        'max': max(latencies),
                        'std': statistics.stdev(latencies) if len(latencies) > 1 else 0,
                        'p95': sorted(latencies)[int(len(latencies) * 0.95)] if len(latencies) > 1 else latencies[0],
                        'p99': sorted(latencies)[int(len(latencies) * 0.99)] if len(latencies) > 1 else latencies[0]
                    }
                }
                summary['pair_analysis'][pair_name] = pair_stats
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        total_valid = len(all_max_latencies)
        total_dropped = len(dropped_sessions)
        total_above_10ms = sum(valid_range_distribution_above_10ms.values())
        
        if total_valid > 0:
            valid_range_percentages = {}
            valid_stage_percentages = {}
            for range_label, count in valid_range_distribution.items():
                valid_range_percentages[range_label] = (count / total_valid) * 100
            
            # è®¡ç®—stageç™¾åˆ†æ¯” (åŸºäº10msä»¥ä¸Šçš„sessions)
            if total_above_10ms > 0:
                for stage, count in valid_stage_distribution.items():
                    valid_stage_percentages[stage] = (count / total_above_10ms) * 100
            
            summary['overall_analysis']['range_percentages'] = valid_range_percentages
            summary['overall_analysis']['stage_percentages'] = valid_stage_percentages
            
            # è®¡ç®—10msä»¥ä¸Šå»¶è¿Ÿçš„ç™¾åˆ†æ¯”
            if total_above_10ms > 0:
                valid_range_percentages_above_10ms = {}
                for range_label, count in valid_range_distribution_above_10ms.items():
                    valid_range_percentages_above_10ms[range_label] = (count / total_above_10ms) * 100
                summary['overall_analysis']['range_percentages_above_10ms'] = valid_range_percentages_above_10ms
        
        if total_dropped > 0:
            dropped_stage_percentages = {}
            drop_reason_percentages = {}
            for stage, count in dropped_stage_distribution.items():
                dropped_stage_percentages[stage] = (count / total_dropped) * 100
            for reason, count in drop_reason_distribution.items():
                drop_reason_percentages[reason] = (count / total_dropped) * 100
            summary['dropped_sessions_analysis']['stage_percentages'] = dropped_stage_percentages
            summary['dropped_sessions_analysis']['drop_reason_percentages'] = drop_reason_percentages
        
        return summary
    
    def format_latency(self, latency_us):
        """æ ¼å¼åŒ–å»¶è¿Ÿæ˜¾ç¤º"""
        if latency_us < 1000:
            return f"{latency_us:.1f} us"
        elif latency_us < 1000000:
            return f"{latency_us/1000:.1f} ms"
        else:
            return f"{latency_us/1000000:.1f} s"
    
    def print_summary(self, summary):
        """æ‰“å°åˆ†æç»“æœ"""
        print(f"\n{'='*100}")
        print(f"é€šç”¨ç½‘ç»œå»¶è¿Ÿåˆ†æSummary")
        print(f"Node Pairs: {len(summary['node_pairs'])}")
        for pair in summary['node_pairs']:
            print(f"  - {pair['pair_name']}: {pair['src_ip']} -> {pair['dst_ip']}")
        print(f"æ€»Sessionæ•°: {summary['total_sessions']}")
        print(f"{'='*100}")
        
        # æ€»ä½“åˆ†æ
        overall_analysis = summary['overall_analysis']
        print(f"\nğŸŸ¢ æ€»ä½“åˆ†æ:")
        print(f"  æœ‰æ•ˆSessionæ•°: {overall_analysis['total_valid_sessions']}")
        print(f"  æœ‰å»¶è¿Ÿæ•°æ®: {overall_analysis['sessions_with_latency']}")
        
        if 'latency_statistics' in overall_analysis:
            stats = overall_analysis['latency_statistics']
            print(f"\n  æ€»ä½“å»¶è¿Ÿç»Ÿè®¡ (æœ€å¤§å»¶è¿Ÿ):")
            print(f"    å¹³å‡å€¼: {self.format_latency(stats['mean'])}")
            print(f"    ä¸­ä½æ•°: {self.format_latency(stats['median'])}")
            print(f"    æœ€å°å€¼: {self.format_latency(stats['min'])}")
            print(f"    æœ€å¤§å€¼: {self.format_latency(stats['max'])}")
            print(f"    æ ‡å‡†å·®: {self.format_latency(stats['std'])}")
            print(f"    95%åˆ†ä½: {self.format_latency(stats['p95'])}")
            print(f"    99%åˆ†ä½: {self.format_latency(stats['p99'])}")
        
        # æ€»ä½“å»¶è¿ŸåŒºé—´åˆ†å¸ƒ
        if 'latency_distribution' in overall_analysis:
            print(f"\n  æ€»ä½“å»¶è¿ŸåŒºé—´åˆ†å¸ƒ:")
            for range_label in self.get_range_order():
                count = overall_analysis['latency_distribution'].get(range_label, 0)
                if count > 0:
                    percent = overall_analysis.get('range_percentages', {}).get(range_label, 0)
                    print(f"    {range_label}: {count} sessions ({percent:.1f}%)")
        
        # æ€»ä½“å»¶è¿Ÿstageåˆ†å¸ƒ (åªæ˜¾ç¤º10msä»¥ä¸Š)
        if 'stage_distribution' in overall_analysis and overall_analysis['stage_distribution']:
            print(f"\n  æ€»ä½“æœ€å¤§å»¶è¿ŸStageåˆ†å¸ƒ (>=10ms):")
            stage_percentages = overall_analysis.get('stage_percentages', {})
            sorted_stages = sorted(overall_analysis['stage_distribution'].items(), 
                                 key=lambda x: x[1], reverse=True)
            
            for stage, count in sorted_stages:
                percent = stage_percentages.get(stage, 0)
                print(f"    {stage}: {count} sessions ({percent:.1f}%)")
        
        # æŒ‰pairè¯¦ç»†åˆ†æ
        print(f"\nğŸ“Š å„Node Pairè¯¦ç»†åˆ†æ:")
        for pair_name, pair_stats in summary['pair_analysis'].items():
            print(f"\n  ğŸ“ {pair_name}:")
            print(f"    æœ‰æ•ˆSessions: {pair_stats['total_sessions']}")
            
            if 'latency_statistics' in pair_stats:
                stats = pair_stats['latency_statistics']
                print(f"    å¹³å‡å»¶è¿Ÿ: {self.format_latency(stats['mean'])}")
                print(f"    ä¸­ä½æ•°: {self.format_latency(stats['median'])}")
                print(f"    95%åˆ†ä½: {self.format_latency(stats['p95'])}")
                print(f"    æœ€å¤§å»¶è¿Ÿ: {self.format_latency(stats['max'])}")
            
            # æ˜¾ç¤ºå»¶è¿Ÿåˆ†å¸ƒï¼ˆåªæ˜¾ç¤ºæœ‰æ•°æ®çš„åŒºé—´ï¼‰
            if 'latency_distribution' in pair_stats:
                print(f"    å»¶è¿Ÿåˆ†å¸ƒ:")
                for range_label in self.get_range_order():
                    count = pair_stats['latency_distribution'].get(range_label, 0)
                    if count > 0:
                        percent = (count / pair_stats['total_sessions']) * 100
                        print(f"      {range_label}: {count} ({percent:.1f}%)")
        
        # ä¸¢åŒ…sessionsåˆ†æ
        dropped_analysis = summary['dropped_sessions_analysis']
        if dropped_analysis['total_dropped_sessions'] > 0:
            print(f"\nğŸ”´ ä¸¢åŒ…Sessionåˆ†æ:")
            print(f"  ä¸¢åŒ…Sessionæ•°: {dropped_analysis['total_dropped_sessions']}")
            
            # ä¸¢åŒ…åŸå› åˆ†å¸ƒ
            if 'drop_reason_distribution' in dropped_analysis:
                print(f"\n  ä¸¢åŒ…åŸå› åˆ†å¸ƒ:")
                drop_reason_percentages = dropped_analysis.get('drop_reason_percentages', {})
                sorted_reasons = sorted(dropped_analysis['drop_reason_distribution'].items(), 
                                      key=lambda x: x[1], reverse=True)
                
                for reason, count in sorted_reasons:
                    percent = drop_reason_percentages.get(reason, 0)
                    print(f"    {reason}: {count} sessions ({percent:.1f}%)")
        
        print(f"\n{'='*100}")
    
    def save_summary(self, summary, filename):
        """ä¿å­˜summaryç»“æœ"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“ Summaryå·²ä¿å­˜: {filename}")
    
    def generate_summary(self):
        """ç”Ÿæˆå®Œæ•´çš„summary"""
        self.load_data()
        summary = self.analyze_sessions()
        return summary

def main():
    import sys
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 general_summary_generator.py <analysis_file>")
        return 1
    
    analysis_file = sys.argv[1]
    
    # åˆ›å»ºsummaryç”Ÿæˆå™¨
    generator = GeneralSummaryGenerator(analysis_file)
    
    # ç”Ÿæˆsummary
    summary = generator.generate_summary()
    
    # æ‰“å°summary
    generator.print_summary(summary)
    
    # ä¿å­˜summary
    output_file = analysis_file.replace('_analysis.json', '_latency_summary.json')
    generator.save_summary(summary, output_file)

if __name__ == "__main__":
    main() 