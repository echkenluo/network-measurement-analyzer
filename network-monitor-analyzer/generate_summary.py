#!/usr/bin/env python3
"""
åŸºäºå®Œæ•´åˆ†ææŠ¥å‘Šç”Ÿæˆæ€»çš„Summary Report
"""

import re
import json
from collections import defaultdict
from datetime import datetime

def parse_report_file(report_file):
    """è§£æå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
    
    with open(report_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ±‡æ€»ç»Ÿè®¡éƒ¨åˆ†
    summary_pattern = r'===== æ±‡æ€»ç»Ÿè®¡ =====(.*?)===== .*? æ¯æ—¥åˆ†ææŠ¥å‘Š ====='
    summary_match = re.search(summary_pattern, content, re.DOTALL)
    
    summary_stats = {}
    if summary_match:
        summary_content = summary_match.group(1)
        
        # è§£æå­˜å‚¨ç½‘ç»œç»Ÿè®¡
        storage_pattern = r'=== å­˜å‚¨ç½‘ç»œ.*?æ€»ä½“ç»Ÿè®¡ ===(.*?)=== ç®¡ç†ç½‘ç»œ'
        storage_match = re.search(storage_pattern, summary_content, re.DOTALL)
        if storage_match:
            storage_content = storage_match.group(1)
            summary_stats['storage'] = parse_network_stats(storage_content)
        
        # è§£æç®¡ç†ç½‘ç»œç»Ÿè®¡
        mgmt_pattern = r'=== ç®¡ç†ç½‘ç»œ.*?æ€»ä½“ç»Ÿè®¡ ===(.*?)$'
        mgmt_match = re.search(mgmt_pattern, summary_content, re.DOTALL)
        if mgmt_match:
            mgmt_content = mgmt_match.group(1)
            summary_stats['management'] = parse_network_stats(mgmt_content)
    
    # è§£ææ¯æ—¥çŸ©é˜µæ•°æ®æ¥è·å–æ›´è¯¦ç»†çš„ç»Ÿè®¡
    daily_stats = parse_daily_matrices(content)
    
    return summary_stats, daily_stats

def parse_network_stats(content):
    """è§£æç½‘ç»œç»Ÿè®¡å†…å®¹"""
    stats = {}
    
    patterns = {
        'total_days': r'æ€»å¤©æ•°: (\d+)',
        'valid_pairs': r'æœ‰æ•ˆIPå¯¹æ•°æ®: ([\d,]+)',
        'theoretical_packets': r'ç†è®ºæ€»åŒ…æ•°: ([\d,]+)',
        'actual_lost': r'å®é™…ä¸¢åŒ…æ•°: ([\d,]+)',
        'actual_latency': r'å®é™…é«˜å»¶è¿Ÿæ•°: ([\d,]+)',
        'loss_rate': r'æ€»ä½“ä¸¢åŒ…ç‡: ([\d.]+)%',
        'latency_rate': r'æ€»ä½“é«˜å»¶è¿Ÿç‡: ([\d.]+)%',
        'ips': r'åŒ…å«IP: (.*?)$'
    }
    
    for key, pattern in patterns.items():
        match = re.search(pattern, content, re.MULTILINE)
        if match:
            value = match.group(1).replace(',', '') if key not in ['loss_rate', 'latency_rate', 'ips'] else match.group(1)
            if key in ['total_days', 'valid_pairs', 'theoretical_packets', 'actual_lost', 'actual_latency']:
                stats[key] = int(value)
            elif key in ['loss_rate', 'latency_rate']:
                stats[key] = float(value)
            else:
                stats[key] = value
    
    return stats

def parse_daily_matrices(content):
    """è§£ææ¯æ—¥çŸ©é˜µæ•°æ®"""
    daily_stats = {
        'storage': defaultdict(lambda: {'total_loss': 0, 'total_latency': 0, 'worst_connections': []}),
        'management': defaultdict(lambda: {'total_loss': 0, 'total_latency': 0, 'worst_connections': []})
    }
    
    # æŸ¥æ‰¾æ‰€æœ‰æ—¥æœŸçš„ä¸¢åŒ…æ•°é‡çŸ©é˜µ
    date_pattern = r'=== (\d{4}-\d{2}-\d{2}) - (å­˜å‚¨ç½‘ç»œ|ç®¡ç†ç½‘ç»œ).*?ã€ä¸¢åŒ…æ•°é‡çŸ©é˜µã€‘(.*?)================'
    
    for match in re.finditer(date_pattern, content, re.DOTALL):
        date = match.group(1)
        network_type = 'storage' if 'å­˜å‚¨ç½‘ç»œ' in match.group(2) else 'management'
        matrix_content = match.group(3)
        
        # è§£æçŸ©é˜µä¸­çš„æ•°å€¼
        lines = matrix_content.strip().split('\n')[2:]  # è·³è¿‡æ ‡é¢˜è¡Œ
        total_daily_loss = 0
        connections = []
        
        for line in lines:
            if line.strip() and not line.startswith('-'):
                parts = line.split()
                if len(parts) > 1:
                    source_ip = parts[0]
                    for i, value in enumerate(parts[1:], 1):
                        if value != 'N/A' and value.replace(',', '').isdigit():
                            loss_count = int(value.replace(',', ''))
                            total_daily_loss += loss_count
                            if loss_count > 1000:  # è®°å½•ä¸¥é‡ä¸¢åŒ…è¿æ¥
                                target_idx = i - 1
                                connections.append({
                                    'source': source_ip,
                                    'loss_count': loss_count,
                                    'target_idx': target_idx
                                })
        
        daily_stats[network_type][date]['total_loss'] = total_daily_loss
        daily_stats[network_type][date]['worst_connections'] = sorted(connections, 
                                                                    key=lambda x: x['loss_count'], 
                                                                    reverse=True)[:5]
    
    return daily_stats

def generate_summary_report(summary_stats, daily_stats):
    """ç”Ÿæˆæ€»çš„Summary Report"""
    
    report_lines = []
    report_lines.append("# é›†ç¾¤ç½‘ç»œç›‘æ§åˆ†ææ€»ç»“æŠ¥å‘Š")
    report_lines.append("")
    report_lines.append("## ğŸ“Š æ•´ä½“ç½‘ç»œè´¨é‡è¯„ä¼°")
    report_lines.append("")
    
    # æ€»ä½“å¯¹æ¯”è¡¨æ ¼
    report_lines.append("| ç½‘ç»œç±»å‹ | è¦†ç›–å¤©æ•° | æœ‰æ•ˆè¿æ¥å¯¹ | æ€»ä½“ä¸¢åŒ…ç‡ | æ€»ä½“é«˜å»¶è¿Ÿç‡ | ç½‘ç»œè´¨é‡è¯„çº§ |")
    report_lines.append("|---------|----------|------------|------------|-------------|------------|")
    
    for net_type in ['storage', 'management']:
        if net_type in summary_stats:
            stats = summary_stats[net_type]
            network_name = "å­˜å‚¨ç½‘ç»œ" if net_type == 'storage' else "ç®¡ç†ç½‘ç»œ"
            
            # è®¡ç®—ç½‘ç»œè´¨é‡è¯„çº§
            loss_rate = stats['loss_rate']
            latency_rate = stats['latency_rate']
            
            if loss_rate < 0.01 and latency_rate < 0.002:
                quality = "ä¼˜ç§€ â­â­â­"
            elif loss_rate < 0.05 and latency_rate < 0.01:
                quality = "è‰¯å¥½ â­â­"
            elif loss_rate < 0.1 and latency_rate < 0.05:
                quality = "ä¸€èˆ¬ â­"
            else:
                quality = "éœ€æ”¹è¿› âš ï¸"
            
            report_lines.append(f"| {network_name} | {stats['total_days']}å¤© | {stats['valid_pairs']:,}å¯¹ | {stats['loss_rate']:.4f}% | {stats['latency_rate']:.4f}% | {quality} |")
    
    report_lines.append("")
    report_lines.append("## ğŸ” å…³é”®å‘ç°")
    report_lines.append("")
    
    # æ¯”è¾ƒä¸¤ä¸ªç½‘ç»œ
    if 'storage' in summary_stats and 'management' in summary_stats:
        storage_loss = summary_stats['storage']['loss_rate']
        mgmt_loss = summary_stats['management']['loss_rate']
        storage_latency = summary_stats['storage']['latency_rate']
        mgmt_latency = summary_stats['management']['latency_rate']
        
        report_lines.append("### ç½‘ç»œç±»å‹å¯¹æ¯”")
        report_lines.append("")
        
        if storage_loss > mgmt_loss:
            diff = storage_loss - mgmt_loss
            report_lines.append(f"- **å­˜å‚¨ç½‘ç»œä¸¢åŒ…ç‡è¾ƒé«˜**: æ¯”ç®¡ç†ç½‘ç»œé«˜ {diff:.4f}%")
        else:
            diff = mgmt_loss - storage_loss
            report_lines.append(f"- **ç®¡ç†ç½‘ç»œä¸¢åŒ…ç‡è¾ƒé«˜**: æ¯”å­˜å‚¨ç½‘ç»œé«˜ {diff:.4f}%")
        
        if storage_latency > mgmt_latency:
            diff = storage_latency - mgmt_latency
            report_lines.append(f"- **å­˜å‚¨ç½‘ç»œå»¶è¿Ÿé—®é¢˜è¾ƒå¤š**: æ¯”ç®¡ç†ç½‘ç»œé«˜ {diff:.4f}%")
        else:
            diff = mgmt_latency - storage_latency
            report_lines.append(f"- **ç®¡ç†ç½‘ç»œå»¶è¿Ÿé—®é¢˜è¾ƒå¤š**: æ¯”å­˜å‚¨ç½‘ç»œé«˜ {diff:.4f}%")
    
    report_lines.append("")
    
    # åˆ†ææœ€ä¸¥é‡çš„é—®é¢˜æ—¥æœŸ
    report_lines.append("## ğŸš¨ é—®é¢˜çƒ­ç‚¹åˆ†æ")
    report_lines.append("")
    
    for net_type in ['storage', 'management']:
        if net_type in daily_stats:
            network_name = "å­˜å‚¨ç½‘ç»œ" if net_type == 'storage' else "ç®¡ç†ç½‘ç»œ"
            report_lines.append(f"### {network_name}é—®é¢˜çƒ­ç‚¹")
            report_lines.append("")
            
            # æ‰¾å‡ºä¸¢åŒ…æœ€ä¸¥é‡çš„æ—¥æœŸ
            worst_days = sorted(daily_stats[net_type].items(), 
                              key=lambda x: x[1]['total_loss'], 
                              reverse=True)[:5]
            
            if worst_days:
                report_lines.append("**ä¸¢åŒ…æœ€ä¸¥é‡çš„æ—¥æœŸ**:")
                report_lines.append("")
                for i, (date, stats) in enumerate(worst_days, 1):
                    total_loss = stats['total_loss']
                    if total_loss > 0:
                        report_lines.append(f"{i}. **{date}**: æ€»ä¸¢åŒ… {total_loss:,} ä¸ª")
                        if stats['worst_connections']:
                            worst_conn = stats['worst_connections'][0]
                            report_lines.append(f"   - æœ€ä¸¥é‡è¿æ¥: {worst_conn['source']} ä¸¢åŒ… {worst_conn['loss_count']:,} ä¸ª")
                report_lines.append("")
    
    # æ•°æ®å®Œæ•´æ€§éªŒè¯
    report_lines.append("## âœ… æ•°æ®å®Œæ•´æ€§")
    report_lines.append("")
    
    for net_type in ['storage', 'management']:
        if net_type in summary_stats:
            stats = summary_stats[net_type]
            network_name = "å­˜å‚¨ç½‘ç»œ" if net_type == 'storage' else "ç®¡ç†ç½‘ç»œ"
            
            # è®¡ç®—ç†è®ºå’Œå®é™…çš„ä¸€è‡´æ€§
            expected_daily_packets = 576000
            actual_avg_daily_packets = stats['theoretical_packets'] / stats['valid_pairs']
            
            report_lines.append(f"### {network_name}")
            report_lines.append(f"- ç†è®ºæ¯æ—¥å‘åŒ…é‡: 576,000åŒ…/IPå¯¹")
            report_lines.append(f"- å®é™…å¹³å‡: {actual_avg_daily_packets:,.0f}åŒ…/IPå¯¹")
            report_lines.append(f"- æ•°æ®å®Œæ•´æ€§: {'âœ… æ­£å¸¸' if abs(actual_avg_daily_packets - expected_daily_packets) < 1000 else 'âš ï¸ å¼‚å¸¸'}")
            report_lines.append("")
    
    # è¶‹åŠ¿åˆ†æ
    report_lines.append("## ğŸ“ˆ ç½‘ç»œè¶‹åŠ¿åˆ†æ")
    report_lines.append("")
    
    # åˆ†ææ—¶é—´è¶‹åŠ¿ï¼ˆåŸºäºæ—¥æœŸï¼‰
    all_dates = set()
    for net_type in daily_stats:
        all_dates.update(daily_stats[net_type].keys())
    
    sorted_dates = sorted(list(all_dates))
    if len(sorted_dates) >= 3:
        early_dates = sorted_dates[:len(sorted_dates)//3]
        late_dates = sorted_dates[-len(sorted_dates)//3:]
        
        for net_type in ['storage', 'management']:
            if net_type in daily_stats:
                network_name = "å­˜å‚¨ç½‘ç»œ" if net_type == 'storage' else "ç®¡ç†ç½‘ç»œ"
                
                early_loss = sum(daily_stats[net_type][date]['total_loss'] 
                               for date in early_dates 
                               if date in daily_stats[net_type])
                late_loss = sum(daily_stats[net_type][date]['total_loss'] 
                              for date in late_dates 
                              if date in daily_stats[net_type])
                
                if early_loss > 0 and late_loss > 0:
                    trend = "æ”¹å–„" if late_loss < early_loss else "æ¶åŒ–" if late_loss > early_loss else "ç¨³å®š"
                    report_lines.append(f"- **{network_name}**: ç½‘ç»œè´¨é‡æ€»ä½“å‘ˆ **{trend}** è¶‹åŠ¿")
    
    report_lines.append("")
    report_lines.append("## ğŸ¯ å»ºè®®")
    report_lines.append("")
    report_lines.append("1. **æŒç»­ç›‘æ§**: ä¿æŒå¯¹ç½‘ç»œè´¨é‡çš„æŒç»­ç›‘æ§")
    report_lines.append("2. **é—®é¢˜é¢„è­¦**: å»ºè®®è®¾ç½®ä¸¢åŒ…ç‡>0.1%çš„å‘Šè­¦é˜ˆå€¼")
    report_lines.append("3. **é‡ç‚¹å…³æ³¨**: å¯¹è¯†åˆ«å‡ºçš„é—®é¢˜èŠ‚ç‚¹è¿›è¡Œé‡ç‚¹ç›‘æ§")
    report_lines.append("4. **å®šæœŸåˆ†æ**: å»ºè®®æ¯å‘¨è¿›è¡Œç½‘ç»œè´¨é‡åˆ†æ")
    
    return '\n'.join(report_lines)

def main():
    """ä¸»å‡½æ•°"""
    report_file = 'corrected_network_analysis_report.txt'
    output_file = 'network_summary_report.md'
    
    print("æ­£åœ¨è§£æå®Œæ•´åˆ†ææŠ¥å‘Š...")
    summary_stats, daily_stats = parse_report_file(report_file)
    
    print("æ­£åœ¨ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
    summary_report = generate_summary_report(summary_stats, daily_stats)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(summary_report)
    
    print(f"æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ° {output_file}")
    
    # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
    print("\n" + "="*50)
    print("æ€»ç»“æŠ¥å‘Šé¢„è§ˆ:")
    print("="*50)
    lines = summary_report.split('\n')
    for line in lines[:30]:  # æ˜¾ç¤ºå‰30è¡Œ
        print(line)
    if len(lines) > 30:
        print("...")

if __name__ == "__main__":
    main() 